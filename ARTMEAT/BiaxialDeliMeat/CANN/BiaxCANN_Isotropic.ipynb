{"cells":[{"cell_type":"markdown","metadata":{"id":"Se438kR0HIri"},"source":["# Automated Model Discovery for Deli Meat\n","\n","Meat Model Discovery Papers:\n","1. \"Discovery the mechanics of artificial and real meat\": https://doi.org/10.1016/j.cma.2023.116236\n","2. \"The mechanical and sensory signature of plant-based and animal meat\": https://www.nature.com/articles/s41538-024-00330-6\n","\n","Code by Skyler St. Pierre, Ethan Darwin, Steven Tran, Kevin Linka \\\\\n","Last edited December 2024\n"]},{"cell_type":"markdown","metadata":{"id":"z-Cbocl8QTO_"},"source":["### 0. Load python packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EMtuCuVn67Ru"},"outputs":[],"source":["!pip install tensorflow==2.12.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vxBfDHBYyRd_"},"outputs":[],"source":["# make sure to only restart session after all 3 packages have finished i.e. hit \"cancel\" on the pop-up after the first two\n","!pip install matplotlib==3.2.2\n","!pip install numpy==1.23.5\n","!pip install pandas==1.5.3"]},{"cell_type":"markdown","metadata":{"id":"Difswvx5cCL4"},"source":["Make sure to select `Runtime` > `Restart Session` as the top of the file before running the next code block!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"koxfCXBQn_9g","collapsed":true},"outputs":[],"source":["# Essentials\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","import numpy as np\n","import pandas as pd\n","import os\n","import copy\n","# ML\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","import tensorflow.keras as keras\n","from tensorflow.keras import regularizers\n","from sklearn.metrics import r2_score\n","# Others\n","import pickle\n","import json\n","import statistics\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","import matplotlib as mpl\n","\n","#!pip install openpyxl\n","\n","# Check Versions\n","print('Numpy: ' + np.__version__)\n","print('Matplotlib: ' + matplotlib.__version__) # 3.2.2\n","print('Tensorflow: ' + tf.__version__) # 2.12.0\n","print('Keras: ' + keras.__version__)\n","print('Pandas: ' + pd.__version__) # 1.5.3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29zqO4O_7GdO"},"outputs":[],"source":["!python --version\n","import sklearn\n","print(sklearn.__version__)\n","print(json.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rGsjGLS7zi5A"},"outputs":[],"source":["#Import excel file, change to match where you saved the file\n","from google.colab import drive\n","drive.mount('/content/drive')\n","path = \"/content/drive/MyDrive/Colab Notebooks/SURI24\" # change to where you download this; must be in Google Drive"]},{"cell_type":"markdown","metadata":{"id":"UgFW_Pp8mWqv"},"source":["###Useful Functions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3AdMCK8mSbD"},"outputs":[],"source":["def makeDIR(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","\n","def flatten(l):\n","    return [item for sublist in l for item in sublist]\n","\n","def r2_score_own(Truth, Prediction):\n","    R2 = r2_score(Truth,Prediction)\n","    return max(R2,0.0)\n","\n","def count_directories(path):\n","    try:\n","        all_items = os.listdir(path)\n","\n","        directories = [item for item in all_items if os.path.isdir(os.path.join(path, item))]\n","        return 1#len(directories)+1\n","    except:\n","        return 0"]},{"cell_type":"markdown","metadata":{"id":"FuvDD-UW3UIa"},"source":["### 1. Load Skin data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hu2wZxsm5j77"},"outputs":[],"source":["# Material to train the CANN for\n","filename_prefix = 'Realpros' # 'Realchicken', 'Realturkey', 'Realham', 'Tofurkyturkey', 'Tofurkyham','Tofurkyhickory', 'Fakepros', 'Realpros'\n","cwd = os.getcwd()\n","\n","# Data Selection\n","zero_data = True # If True, data starts from lambda=1, sigma=0\n","truncate_data = 21 # Number of data points per loading mode (strip-x, off-x, etc.)"]},{"cell_type":"markdown","metadata":{"id":"bOZnxYJbqT9B"},"source":["###Import Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A7AO82DOqYil"},"outputs":[],"source":["# Make sure you have right data directory as: pd.read_excel('data location')\n","# break_list = where to trim the data (or equal to data size of each biaxial mode)\n","\n","if filename_prefix=='Realchicken':\n","    df_MechData = pd.read_excel(path + '/Input/rm_chicken_results.xlsx')\n","    break_list = [truncate_data,truncate_data+21,truncate_data+42,truncate_data+63,truncate_data+84]\n","elif filename_prefix=='Realturkey':\n","    df_MechData = pd.read_excel(path + '/Input/rm_turk_homo_results.xlsx')\n","    break_list = [truncate_data,truncate_data+21,truncate_data+42,truncate_data+63,truncate_data+84]\n","elif filename_prefix=='Realham':\n","    df_MechData = pd.read_excel(path + '/Input/rm_ham_homo_results.xlsx')\n","    break_list = [truncate_data,truncate_data+21,truncate_data+42,truncate_data+63,truncate_data+84]\n","elif filename_prefix=='Tofurkyturkey':\n","    df_MechData = pd.read_excel(path + '/Input/tf_turk_rake_results.xlsx')\n","    break_list = [truncate_data,truncate_data+21,truncate_data+42,truncate_data+63,truncate_data+84]\n","elif filename_prefix=='Tofurkyham':\n","    df_MechData = pd.read_excel(path + '/Input/tf_ham_results.xlsx')\n","    break_list = [truncate_data,truncate_data+21,truncate_data+42,truncate_data+63,truncate_data+84]\n","elif filename_prefix=='Tofurkyhickory':\n","    df_MechData = pd.read_excel(path + '/Input/tf_hick_results.xlsx')\n","    break_list = [truncate_data,truncate_data+21,truncate_data+42,truncate_data+63,truncate_data+84]\n","elif filename_prefix=='Realpros':\n","    df_MechData = pd.read_excel(path + '/Input/rm_pros_results.xlsx')\n","    break_list = [truncate_data,truncate_data+21,truncate_data+42,truncate_data+63,truncate_data+84]\n","elif filename_prefix=='Fakepros':\n","    df_MechData = pd.read_excel(path + '/Input/fm_pros_results.xlsx')\n","    break_list = [truncate_data,truncate_data+21,truncate_data+42,truncate_data+63,truncate_data+84]\n","elif filename_prefix=='Tofurkyturkey_clamp':\n","    df_MechData = pd.read_excel(path + '/Input/tf_turk_clamp_results.xlsx')\n","    break_list = [truncate_data,truncate_data+21,truncate_data+42,truncate_data+63,truncate_data+84]\n","else:\n","    ValueError()\n","\n","# Data conversion\n","lambda_x =  df_MechData['lambda_x'].to_numpy()\n","sigma_xx =  df_MechData['sigma_xx[kPa]'].to_numpy()\n","\n","lambda_y =  df_MechData['lambda_y'].to_numpy()\n","sigma_yy =  df_MechData['sigma_yy[kPa]'].to_numpy()\n","\n","# Seperate data from each biaxial mode\n","st=0\n","all_lam_x = []\n","all_lam_y = []\n","all_Sigma_xx = []\n","all_Sigma_yy = []\n","for i, end in enumerate(break_list): # has no effect if data already starts at lambda=1, stress=0 for each mode\n","    all_lam_x.append(lambda_x[st:end]-(lambda_x[st]-1)*zero_data)\n","    all_lam_y.append(lambda_y[st:end]-(lambda_y[st]-1)*zero_data)\n","    all_Sigma_xx.append(sigma_xx[st:end]-sigma_xx[st]*zero_data)\n","    all_Sigma_yy.append(sigma_yy[st:end]-sigma_yy[st]*zero_data)\n","    st = end + 1"]},{"cell_type":"markdown","metadata":{"id":"Qdsxsk3V1cZp"},"source":["### L1 and L2 regularization with penalty weight\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDqcHT6r1a8J"},"outputs":[],"source":["def regularize(reg, pen):\n","    if reg == 'L2':\n","        return keras.regularizers.l2(pen)\n","    if reg == 'L1':\n","        return keras.regularizers.l1(pen)"]},{"cell_type":"markdown","source":["## 2. Strain Energy Model - Invariant-based\n","<figure>\n","<center>\n","<img src='https://drive.google.com/uc?export=view&id=1-0eM6j7CP_jzSXM_AswZU8P7-IzEN1I5'/>\n","<figcaption>Isotropic CANN</figcaption></center>\n","</figure>\n","\n"],"metadata":{"id":"eHiciZ4umneL"}},{"cell_type":"markdown","source":["Next, we define the strain energy function for our transversely isotropic, perfectly incompressible Constitutive Artificial Neural Network with two hidden layers and 8 nodes using the invariants of the right Cauchy Green tensor. The first layer generates powers $(\\circ)^1$ and $(\\circ)^2$ of the network inputs,\n","$[I_1-3]$, $[I_2-3]$, and the second layer applies the identity, $(\\circ)$ and the exponential function, $(\\rm{exp}((\\circ))-1)$.\n","The set of equations for this networks takes the following explicit form,\n","\n","$$\n","\\begin{equation}\n","\\begin{split}\n","\\psi(I_1,I_2) &= w_{1} w_{1}^*[I_1-3] + w_{2}[\\exp(w_{2}^*[I_1-3])-1]\\\\\n","& + w_{3} w_{3}^*[I_1-3]^2  + w_{4}[\\exp(w_{4}^*[I_1-3]^2)-1] \\\\\n","& + w_{5} w_{5}^*[I_2-3] + w_{6}[\\exp(w_{6}^*[I_2-3])-1] \\\\\n","& + w_{7} w_{7}^*[I_2-3]^2 + w_{8}[\\exp(w_{8}^*[I_2-3]^2)-1]\\\\\n","\\end{split}\n","\\end{equation}\n","$$\n","\n","First we define the activation functions and a single Invariant block:"],"metadata":{"id":"EvFHhzRpmSJ_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Jbyl-Tt2vJt"},"outputs":[],"source":["# Initializers (look up https://keras.io/api/layers/initializers/ for more)\n","initializer_1 = 'glorot_normal'\n","initializer_zero = 'zeros'\n","initializer_log = 'glorot_normal'\n","initializer_exp = tf.keras.initializers.RandomUniform(minval=0.5, maxval=2.5) # worked off and on, starts with huge residual\n","initializer_exp2 = tf.keras.initializers.RandomUniform(minval=0.01, maxval=0.1)\n","\n","# Self defined activation functions for exp term\n","def activation_Exp(x):\n","    return 1.0*(tf.math.exp(x) -1.0)\n","# Self defined activation functions for ln term\n","def activation_ln(x):\n","    return -1.0*tf.math.log(1.0 - (x))\n","\n","# Define Invariant building-blocks(linear, quad, exp, exp-quad, ln)\n","def SingleInvNet_5(I1_ref,idi,reg,pen):\n","    I_1_w11 = keras.layers.Dense(1,kernel_initializer=initializer_1,kernel_constraint=keras.constraints.NonNeg(),\n","                                 kernel_regularizer=regularize(reg, pen),\n","                                 use_bias=False, activation=None,name='w'+str(1+idi)+'1')(I1_ref)\n","    I_1_w21 = keras.layers.Dense(1,kernel_initializer=initializer_exp,kernel_constraint=keras.constraints.NonNeg(),\n","                                 kernel_regularizer=regularize(reg, pen),\n","                                 use_bias=False, activation=activation_Exp,name='w'+str(2+idi)+'1')(I1_ref)\n","\n","    I_1_w31 = keras.layers.Dense(1,kernel_initializer=initializer_1,kernel_constraint=keras.constraints.NonNeg(),\n","                                 kernel_regularizer=regularize(reg, pen),\n","                                 use_bias=False, activation=None,name='w'+str(3+idi)+'1')(tf.math.square(I1_ref))\n","    I_1_w41 = keras.layers.Dense(1,kernel_initializer=initializer_exp,kernel_constraint=keras.constraints.NonNeg(),\n","                                 kernel_regularizer=regularize(reg, pen),\n","                                 use_bias=False, activation=activation_Exp,name='w'+str(4+idi)+'1')(tf.math.square(I1_ref))\n","\n","    collect = [I_1_w11, I_1_w21, I_1_w31, I_1_w41]\n","    collect_out = tf.keras.layers.concatenate(collect, axis=1)\n","\n","    return collect_out\n","\n","# Define Invariant building-blocks(linear, quad, exp, ln)\n","def SingleInvNet_4(I1_ref,idi,reg,pen):\n","    I_1_w11 = keras.layers.Dense(1,kernel_initializer=initializer_1,kernel_constraint=keras.constraints.NonNeg(),\n","                                 kernel_regularizer=regularize(reg, pen),\n","                                 use_bias=False, activation=None,name='w'+str(1+idi)+'1')(I1_ref)\n","    I_1_w21 = keras.layers.Dense(1,kernel_initializer=initializer_exp,kernel_constraint=keras.constraints.NonNeg(),\n","                                 kernel_regularizer=regularize(reg, pen),\n","                                 use_bias=False, activation=activation_Exp,name='w'+str(2+idi)+'1')(I1_ref)\n","    I_1_w31 = keras.layers.Dense(1,kernel_initializer=initializer_1,kernel_constraint=keras.constraints.NonNeg(),\n","                                 kernel_regularizer=regularize(reg, pen),\n","                                 use_bias=False, activation=None,name='w'+str(3+idi)+'1')(tf.math.square(I1_ref))\n","\n","    collect = [I_1_w11, I_1_w21, I_1_w31]\n","    collect_out = tf.keras.layers.concatenate(collect, axis=1)\n","\n","    return collect_out"]},{"cell_type":"markdown","metadata":{"id":"QjNgzkY63fQ7"},"source":["Then we define the strain energy keras submodel as:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-wDqgN2F1m4l"},"outputs":[],"source":["def StrainEnergy_i5(reg,pen):\n","\n","    # Inputs defined\n","    I1_in = tf.keras.Input(shape=(1,), name='I1')\n","    I2_in = tf.keras.Input(shape=(1,), name='I2')\n","\n","    # Invariants reference config\n","    I1_ref = keras.layers.Lambda(lambda x: (x-3.0))(I1_in)\n","    I2_ref = keras.layers.Lambda(lambda x: (x-3.0))(I2_in)\n","\n","    I1_out = SingleInvNet_5(I1_ref,0,reg,pen)\n","    terms = I1_out.get_shape().as_list()[1]\n","    I2_out = SingleInvNet_5(I2_ref,terms,reg,pen)\n","\n","    ALL_I_out = tf.keras.layers.concatenate([I1_out,I2_out],axis=1)\n","\n","    # second layer\n","    W_ANN = keras.layers.Dense(1,kernel_initializer=initializer_1,kernel_constraint=keras.constraints.NonNeg(),\n","                               kernel_regularizer=regularize(reg, pen),\n","                               use_bias=False, activation=None,name='wx2')(ALL_I_out)\n","    Psi_model = keras.models.Model(inputs=[I1_in, I2_in], outputs=[W_ANN], name='Psi')\n","\n","    return Psi_model, terms*2"]},{"cell_type":"markdown","metadata":{"id":"tm8k_7Ve3yAb"},"source":["### 3. Stress Models\n","\n","\n","####  Biaxial Tension\n","\n","For the case of biaxial tension, we stretch the specimen in two directions,\n","$F_{11} = \\lambda_1 = \\lambda$ and $F_{22} = \\lambda_2 = \\lambda$.\n","For an isotropic, perfectly incompressible material with\n","$I_3 = \\lambda_1^2  \\lambda_2^2  \\lambda_3^2 = 1$,\n","the stretch orthogonal to the loading directions are identical and equal to the inverse square of the stretch,\n","$F_{33} = \\lambda_3 = \\lambda^{-2}$.\n","From the resulting deformation gradient,\n","$\\mathbf{F}= {\\rm{diag}} \\, \\{ \\; \\lambda, \\lambda, \\lambda^{-2} \\,\\}$,\n","we calculate the invariants and their derivatives,\n","\n","$$\n","\\begin{align*}\n","    I_{1} &= {\\lambda_{1}}^2+{\\lambda_{2}}^2+\\frac{1}{{\\lambda_{1}}^2{\\lambda_{2}}^2} && \\frac{\\partial I_{1}}{\\partial\\mathbf{F}} = 2\\,\\text{diag}\\left\\{\\lambda_{1},\\lambda_{2},\\frac{1}{\\lambda_{1}\\lambda_{2}}\\right\\}\\\\\n","    I_{2} &= {\\lambda_{1}}^2{\\lambda _{2}}^2+\\frac{1}{{\\lambda_{1}}^2}+\\frac{1}{{\\lambda_{2}}^2} && \\frac{\\partial I_{2}}{\\partial\\mathbf{F}} = 2\\,\\text{diag}\\left\\{ \\lambda_{1}{\\lambda_{2}}^{2}+\\frac{1}{\\lambda_{1}{\\lambda_{2}}^{2}},{\\lambda_{1}}^{2}\\lambda_{2}+\\frac{1}{{\\lambda _{1}}^{2}\\lambda_{2}},\\frac{\\lambda_{1}}{\\lambda_{2}}+\\frac{\\lambda_{2}}{\\lambda_{1}}\\right\\}\\\\\n","    I_{3} &= 1 && \\frac{\\partial I_{3}}{\\partial\\mathbf{F}} = 2\\,\\text{diag}\\left\\{\\frac{1}{\\lambda_{1}},\\frac{1}{\\lambda_{2}},\\lambda_{1}\\lambda_{2}\\right\\}\\\\\n","\\end{align*}\n","$$\n","\n","to evaluate the nominal biaxial stress $P_{11}$\n","using the general stress-stretch relationship for perfectly incompressible materials,\n","$ \\begin{equation*}\n","    \\mathbf{P}=\\frac{\\partial \\psi_{1}}{\\partial I_{1}}\\frac{\\partial I_{1}}{\\partial \\mathbf{F}} + \\frac{\\partial \\psi_{2}}{\\partial I_{2}}\\frac{\\partial I_{2}}{\\partial \\mathbf{F}} - p\\mathbf{F}^{-t}\n","\\end{equation*}$.\n","Here, $p$ denotes the hydrostatic pressure that we determine from the zero stress condition in the transverse directions, $P_{33} = 0$, as\n","$ \\begin{equation*}\n","    p=\\frac{2}{{\\lambda_{1}}^{2}{\\lambda_{2}}^{2}}\\frac{\\partial \\psi_{1}}{\\partial I_{1}}\\left(\\frac{1}{{\\lambda_{1}}^{2}}+\\frac{1}{{\\lambda_{2}}^{2}}\\right)\n","\\end{equation*}.$\n","This results in the following explicit biaxial stress-stretch relation for perfectly incompressible, transversely isotropic materials,\n","\n","$$\n","\\begin{align*}\n","    P_{11}=2\\left(\\lambda_{1}-\\frac{1}{{\\lambda_{1}}^{3}{\\lambda_{2}}^{2}}\\right)\\frac{\\partial \\psi_{1}}{\\partial I_{1}} + 2\\left(\\lambda_{1}{\\lambda_{2}}^{2} - \\frac{1}{{\\lambda_{1}}^{3}} \\right)\\frac{\\partial \\psi_{2}}{\\partial I_{2}}\\\\\n","    P_{22}=2\\left(\\lambda_{2}-\\frac{1}{{\\lambda_{1}}^{2}{\\lambda_{2}}^{3}}\\right)\\frac{\\partial \\psi_{1}}{\\partial I_{1}} + 2\\left({\\lambda_{1}}^{2}\\lambda_{2} - \\frac{1}{{\\lambda_{2}}^{3}}\\right)\\frac{\\partial \\psi_{2}}{\\partial I_{2}}\n","\\end{align*}\n","$$\n","\n","Reference: https://doi.org/10.1016/j.actbio.2024.09.051"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SUj9Kf5y3vAQ"},"outputs":[],"source":["# Definition of stress\n","def Stress_xx_I5_BT(inputs):\n","    (dPsidI1, dPsidI2, Stretch, Stretch_z, I1) = inputs\n","    # stretch_z = 1/(stretch_x*stretch_y)\n","\n","    # calculate piola stress\n","    one = tf.constant(1.0,dtype='float32')\n","    two = tf.constant(2.0,dtype='float32')\n","    four = tf.constant(4.0,dtype='float32')\n","\n","    stress_1 = two*dPsidI1*(Stretch-(Stretch_z**two)/Stretch)\n","    stress_2 = two*dPsidI2 *(one/(Stretch_z**two)/Stretch - Stretch**(-3))\n","\n","    return stress_1 + stress_2"]},{"cell_type":"markdown","metadata":{"id":"eTwDkRFm4BWf"},"source":["Finally, we can define seperate stress models for tension/compression, shear and a combination of all loading states."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZLlSaN-P4EHU"},"outputs":[],"source":["# Gradient function\n","def myGradient(a, b):\n","    der = tf.gradients(a, b, unconnected_gradients='zero')\n","    return der[0]\n","\n","# Complete model architecture definition\n","def modelArchitecture_I5(Psi_model):\n","    # Stretch as input\n","    Stretch_x = keras.layers.Input(shape = (1,),\n","                                  name = 'Stretch_x')\n","    Stretch_y = keras.layers.Input(shape = (1,),\n","                                  name = 'Stretch_y')\n","\n","    # Specific Invariants BT\n","    Stretch_z = tf.keras.layers.Lambda(lambda x: 1/(x[0] * x[1]), name = 'lam_z')([Stretch_x, Stretch_y])\n","    I1_BT = tf.keras.layers.Lambda(lambda x: x[0]**2 + x[1]**2 +x[2]**2, name = 'I1')([Stretch_x, Stretch_y, Stretch_z])\n","    I2_BT = tf.keras.layers.Lambda(lambda x: (x[0]**2)*(x[1]**2) + 1/x[0]**2 + 1/x[1]**2, name = 'I2')([Stretch_x, Stretch_y])\n","\n","    # Define Strain Energy\n","    Psi_BT = Psi_model([I1_BT, I2_BT])\n","\n","    # Derivative DWdX\n","    dWI1_BT  = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_BT, I1_BT])\n","    dWdI2_BT = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_BT, I2_BT])\n","\n","    # Stress XX\n","    Stress_xx_BT = keras.layers.Lambda(function = Stress_xx_I5_BT,\n","                                name = 'Stress_xx_BT')([dWI1_BT, dWdI2_BT,\n","                                                        Stretch_x, Stretch_z, I1_BT])\n","    # Stress YY\n","    Stress_yy_BT = keras.layers.Lambda(function = Stress_xx_I5_BT,\n","                                name = 'Stress_yy_BT')([dWI1_BT, dWdI2_BT,\n","                                                        Stretch_y, Stretch_z, I1_BT])\n","\n","    # Define model\n","    model_BT = keras.models.Model(inputs=[Stretch_x, Stretch_y],  outputs= [Stress_xx_BT, Stress_yy_BT])\n","\n","    return model_BT\n"]},{"cell_type":"markdown","metadata":{"id":"saYHO1e24JMm"},"source":["### 4. Compile model\n","\n","The compiler definition comprises the loss function definition (here a mean squared error metric), the optimizer (here an Adam optimizer) and the evaluation metric (also mean squared error).\n","\n","Moreover, we define model callbacks and the keras fit function. The latter obtains the information about which model we want to fit with which data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NmCtDWke4J5Y"},"outputs":[],"source":["# Optimization utilities\n","def Compile_and_fit(model_given, input_train, output_train, epochs, path_checkpoint, batch_size, validation_split):\n","\n","    mse_loss = keras.losses.MeanSquaredError()\n","    metrics  =[keras.metrics.MeanSquaredError()]\n","    opti1    = tf.optimizers.Adam(learning_rate=0.001)\n","\n","    model_given.compile(loss=mse_loss,\n","                  optimizer=opti1,\n","                  metrics=metrics)\n","\n","\n","    es_callback = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0, patience=2000, restore_best_weights=True)\n","\n","    modelckpt_callback = keras.callbacks.ModelCheckpoint(\n","    monitor=\"loss\",\n","    filepath=path_checkpoint,\n","    verbose=0,\n","    save_weights_only=True,\n","    save_best_only=True,\n","    )\n","\n","    history = model_given.fit(input_train,\n","                        output_train,\n","                        batch_size=batch_size,\n","                        epochs=epochs,\n","                        validation_split=validation_split,\n","                        callbacks=[es_callback, modelckpt_callback],\n","                        shuffle = True,\n","                        verbose = 0,\n","                        # sample_weight = sample_weights\n","                        )\n","\n","    return model_given, history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qnlPxR4dnrE_"},"outputs":[],"source":["def R2xy(all_Sigma_xx, all_Sigma_yy, Stress_predicted):\n","    R2x_all = []\n","    R2y_all = []\n","    for k in range(len(all_Sigma_xx)):\n","        R2x = r2_score_own(all_Sigma_xx[k], Stress_predicted[k][0])\n","        R2y = r2_score_own(all_Sigma_yy[k], Stress_predicted[k][1])\n","        R2x_all.append(R2x)\n","        R2y_all.append(R2y)\n","\n","    return R2x_all, R2y_all"]},{"cell_type":"markdown","metadata":{"id":"ZwHIjb4g4Pni"},"source":["### 5. Plot functions\n","\n","Here we define some plot functions to be used to plot the results later on"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yT9Nfkj4QaD"},"outputs":[],"source":["ColorI = [1.0, 0.65, 0.0]\n","ColorS = [0.5, 0.00, 0.0]\n","#c_lis = ['b','g','r','k','m']\n","#c_lis = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n","c_lis = ['#9c0203', '#80cafd', '#4c7ffe', '#1a34ff', '#070096']\n","\n","# Useful functions\n","def r2_score_own(Truth, Prediction):\n","    R2 = r2_score(Truth,Prediction)\n","    return max(R2,0.0)\n","\n","def GetZeroList(model_weights):\n","    model_zeros = []\n","    for i in range(len(model_weights)):\n","        model_zeros.append(np.zeros_like(model_weights[i]))\n","    return model_zeros\n","\n","# Loss plot\n","def plotLoss(axe, history):\n","    axe.plot(history)\n","    axe.set_yscale('log')\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iOYoQXHk4XfL"},"outputs":[],"source":["# plot the contribution of each term to the model stress prediction\n","def color_map(ax2, lamx, lamy,lamplot, model_BT, model_weights, Psi_model, cmaplist, terms, label,ticks):\n","    predictions = np.zeros([lamx.shape[0],terms])\n","    cmap_r = list(reversed(cmaplist))\n","    model_plot = copy.deepcopy(model_weights)  # deep copy model weights\n","\n","    areas=[]\n","    for i in range(terms):\n","        model_plot[-1] = np.zeros_like(model_weights[-1])  # wx2 all set to zero\n","        model_plot[-1][i] = model_weights[-1][i]  # wx2[i] set to trained value\n","\n","        Psi_model.set_weights(model_plot)\n","        lower = np.sum(predictions,axis=1)\n","        if label == 'x':\n","            upper = lower +  model_BT.predict([lamx, lamy])[0][:].flatten()\n","            predictions[:,i] = model_BT.predict([lamx, lamy])[0][:].flatten()\n","            # ax2.fill_between(lamplot[:], lower.flatten(), upper.flatten(), zorder=i+1, lw=0, color=cmap_r[i])\n","        else:\n","            upper = lower +  model_BT.predict([lamx, lamy])[1][:].flatten()\n","            predictions[:,i] = model_BT.predict([lamx, lamy])[1][:].flatten()\n","\n","        # print(lower,upper)\n","        p=ax2.fill_between(lamplot[:], lower.flatten(), upper.flatten(), zorder=i+1, lw=0, label=ticks[i], color=cmap_r[i])\n","        areas.append(p)\n","\n","    return areas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tt5Fokjg4ags"},"outputs":[],"source":["# Stress-strain plot with colormap\n","def plotMap(fig, fig_ax1, Psi_model, model_weights, model_BT, terms, lamx, lamy, lamplot, P_ut_all, Stress_predict_UT, R2,label, cy, titletype):\n","    tick_arr = list(np.flip(np.arange(terms+4))+0.5)\n","    tick_label = [r'$I_1$',r'$\\exp(I_1)$',r'$I_1^2$',r'$\\exp(I_1^2)$',\n","                  r'$I_2$',r'$\\exp(I_2)$',r'$I_2^2$', r'$\\exp(I_2^2)$']\n","\n","    if titletype == 'separate':\n","      title_label = [\"off-x\",\"off-y\",\"equi-biax\",\"strip-x\",\"strip-y\"]\n","    elif  titletype == 'combine':\n","      title_label = [\"off-x\",\"off-y\",\"equi-biax\",\"strip-x/strip-y\"]\n","    end\n","\n","\n","    cmap = plt.cm.get_cmap('jet',8)   # define the colormap\n","    cmaplist = [cmap(i) for i in range(cmap.N)]\n","\n","    myhandles=[]\n","    s1=fig_ax1.scatter(lamplot, P_ut_all, s=40, zorder=103,lw=1, facecolors='w', edgecolors='k',clip_on=False,label='Data')\n","    p1=fig_ax1.plot(lamplot, Stress_predict_UT, color='k',zorder=25, lw=1);\n","\n","    areas=color_map(fig_ax1, lamx, lamy,lamplot, model_BT, model_weights, Psi_model, cmaplist, terms, label,tick_label)\n","\n","\n","    fig_ax1.text(0.02,0.83,'R2: '+f\"{R2:.2f}\",transform=fig_ax1.transAxes,fontsize=14, horizontalalignment='left',color='k')\n","\n","    fig_ax1.set_title(title_label[cy])\n","\n","    fig_ax1.grid(False)\n","    fig_ax1.set_xticks([round(min(lamplot),2),round(max(lamplot),2)])\n","    fig_ax1.set_yticks([round(min(P_ut_all),2),round(max(P_ut_all),2)])\n","\n","\n","    # plt.tight_layout()\n","    fig_ax1.set_ylabel(r'Piola stress $P$ [kPa]',fontsize='x-large')\n","    fig_ax1.set_xlabel(r'stretch $\\lambda_'+label+'$ [-]',fontsize='x-large')\n","\n","    myhandles.append(s1)\n","    for i in areas:\n","        myhandles.append(i)\n","    return myhandles"]},{"cell_type":"markdown","metadata":{"id":"qVRbZjO_4jBw"},"source":["### 6. Model Training\n","\n","Parameters and definitions for the model training. Try changing the number of epochs and toggling between the invariant and principal-stretch-based model. Make sure to rename the model_type variable for each test."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqeeGfNH4iNq"},"outputs":[],"source":["filename_suffix = '_CANN1' #for directory name / version tracking\n","filename = filename_prefix+filename_suffix\n","\n","# Training settings\n","epochs = 10000 #10000\n","batch_size = 8 #32\n","validation_split = 0\n","\n","### Choose regularization type & penalty amount\n","# Option: 'L1', 'L2'\n","reg = 'L1'\n","pen = 0.01  # Use 0 for no regularization 0.001, 0.01, and 0.1\n","#folder_name = 'L2Reg0.1' # name the folder for your results\n","#folder_name = str(reg) + 'Reg' + str(pen) # name the folder for your results\n","folder_name = 'correctedPiola_L1p01'\n","\n","### Choose which loading modes to train with\n","modelFit_mode_all = ['all'] # which biaxial mode to use\n","\n","# Other settings\n","model_type = 'Model_p'\n","weight_flag = True\n","weight_plot_Map_combine = True\n","weight_plot_Map_seperate = False\n","train = True"]},{"cell_type":"markdown","metadata":{"id":"k3maAROEp3hZ"},"source":["###Set Directories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ld3Q0P7_pzCJ"},"outputs":[],"source":["# e.g) Make Results/Porcine_skin5/Model_p_0\n","# The last number increments to prevent overwriting existing folders.\n","#path2saveResults_0 = path+os.path.join('/Results',filename,model_type+'_'+str(count_directories(os.path.join(os.getcwd(),'Results',filename))))\n","path2saveResults_0 = path + '/Results/'+filename+'/'+folder_name\n","\n","makeDIR(path2saveResults_0)\n","Model_summary = os.path.join(path2saveResults_0, 'Model_summary.txt')\n","path2saveResults = path2saveResults_0\n","path2saveResults_check = os.path.join(path2saveResults,'Checkpoints')\n","makeDIR(path2saveResults)\n","makeDIR(path2saveResults_check)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_cr_iic5pvFU"},"outputs":[],"source":["R2_all = np.zeros([10, len(modelFit_mode_all)])\n","R2_pick = np.zeros([2, len(modelFit_mode_all)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qYkzZBq_PG1r"},"outputs":[],"source":["#  Training and validation loop\n","# train = False\n","for id1, modelFit_mode in enumerate(modelFit_mode_all):\n","    # Terminal display\n","    print(40*'=')\n","    # print('Comp '+str(count)+'/'+str())\n","    print(\"Comp {:d} / {:d}\".format(id1+1, len(modelFit_mode_all)))\n","    print(40*'=')\n","    print(\"Fitting Mode: \", modelFit_mode)\n","    print(40*'=')\n","\n","    # Set directories\n","    path2saveResults = os.path.join(path2saveResults_0, modelFit_mode)\n","    path2saveResults_check = os.path.join(path2saveResults,'Checkpoints')\n","    makeDIR(path2saveResults)\n","    makeDIR(path2saveResults_check)\n","    Save_path = path2saveResults + '//model.h5'\n","    Save_weights = path2saveResults + '//weights'\n","    Stored_weights = path2saveResults_0 + '//weights'\n","    path_checkpoint = path2saveResults_check + '//best_weights'\n","\n","    Psi_model, terms = StrainEnergy_i5(reg,pen)\n","    model_BT = modelArchitecture_I5(Psi_model)\n","    model_given = model_BT\n","\n","    # Model summary\n","    with open(Model_summary,'w') as fh:\n","        # Pass the file handle in as a lambda function to make it callable\n","        Psi_model.summary(line_length=80, print_fn=lambda x: fh.write(x + '\\n'))\n","\n","    # Split training and validation data\n","    if modelFit_mode == 'all':\n","        input_train = [np.concatenate(all_lam_x), np.concatenate(all_lam_y)]\n","        output_train = [np.concatenate(all_Sigma_xx), np.concatenate(all_Sigma_yy)]\n","    else:\n","        input_train = [all_lam_x[id1-1], all_lam_y[id1-1]]\n","        output_train = [all_Sigma_xx[id1-1], all_Sigma_yy[id1-1]]\n","\n","    if train: # train and save the model\n","        if modelFit_mode =='all':\n","            pass\n","        else:\n","            model_given.load_weights(os.path.join(path2saveResults_0, 'all') + '//weights', by_name=False, skip_mismatch=False)\n","\n","        model_given, history = Compile_and_fit(model_given, input_train, output_train,\n","                                                epochs, path_checkpoint, batch_size, validation_split)\n","\n","        model_given.load_weights(path_checkpoint, by_name=False, skip_mismatch=False)\n","        tf.keras.models.save_model(model_given, Save_path, overwrite=True)\n","        model_given.save_weights(Save_weights, overwrite=True)\n","\n","        loss_history = history.history['loss']\n","        fig, axe = plt.subplots(figsize=[6, 5])  # inches\n","        plotLoss(axe, loss_history)\n","        plt.savefig(path2saveResults+'/Plot_loss_'+modelFit_mode+'.pdf')\n","        plt.close()\n","\n","    else: # load existing model only\n","        model_given.load_weights(Save_weights, by_name=False, skip_mismatch=False)\n","\n","    # Get model response\n","    Stress_predicted = []\n","    for j in range(len(all_lam_x)):\n","        Stress_pre = model_BT.predict([all_lam_x[j], all_lam_y[j]])\n","        Stress_predicted.append(Stress_pre)\n","\n","    # R2 evaluation\n","    R2x_all, R2y_all = R2xy(all_Sigma_xx, all_Sigma_yy, Stress_predicted)\n","\n","    # Terminal Display: End of training\n","    print('='*30)\n","\n","    weight_matrix = np.empty((terms, 2))\n","    for i in range(terms):\n","      value = Psi_model.get_weights()[i][0][0]\n","      weight_matrix[i, 0] = value # inner layer is first column\n","    weight_matrix[:, 1] = Psi_model.get_layer('wx2').get_weights()[0].flatten() # outer layer is second column\n","\n","\n","    print(\"weight_matrix\")\n","    print(weight_matrix)\n","\n","\n","    # Plot Color map\n","    model_weights_0 = Psi_model.get_weights()\n","    if weight_plot_Map_seperate:\n","        for kk in range(len(all_lam_x)):\n","            fig2 = plt.figure(figsize=(1200/72,600/72))\n","            spec2 = gridspec.GridSpec(ncols=1, nrows=2, figure=fig2)\n","            ax1 = fig2.add_subplot(spec2[0,0])\n","            ax2 = fig2.add_subplot(spec2[1,0])\n","            plotMap(fig2, ax1, Psi_model, model_weights_0, model_BT,\n","                            terms, all_lam_x[kk], all_lam_y[kk], all_lam_x[kk], all_Sigma_xx[kk], Stress_predicted[kk][0], R2x_all[kk], 'x',kk,'separate')\n","            areas = plotMap(fig2, ax2, Psi_model, model_weights_0, model_BT,\n","                            terms, all_lam_x[kk], all_lam_y[kk], all_lam_y[kk], all_Sigma_yy[kk], Stress_predicted[kk][1], R2x_all[kk], 'y',kk,'separate')\n","\n","            fig2.tight_layout()\n","            fig2.legend(handles=areas,loc='outside lower center', ncol=22, fancybox=False)\n","            plt.savefig(path2saveResults+'//Plot_PI-CANN_MAP_'+modelFit_mode+'_cy_'+str(kk+1)+'.pdf')\n","            plt.close()\n","\n","    fig3 = plt.figure(figsize=(1200/72,600/72))\n","    # figsize=(12.5, 8.33)\n","    spec3 = gridspec.GridSpec(ncols=4, nrows=2, figure=fig3)\n","    if weight_plot_Map_combine:\n","        for kk in range(len(all_lam_x)):\n","            if kk<4: #x plot: off-x, off-y, equibiax, strip-x\n","                ax1 = fig3.add_subplot(spec3[0,kk])\n","                areas=plotMap(fig3, ax1, Psi_model, model_weights_0, model_BT,\n","                              terms, all_lam_x[kk], all_lam_y[kk], all_lam_x[kk], all_Sigma_xx[kk], Stress_predicted[kk][0], R2x_all[kk],'x',kk,'combine')\n","            if kk<3: #y plot: off-x, off-y, equibiax\n","                ax2 = fig3.add_subplot(spec3[1,kk])\n","                areas=plotMap(fig3, ax2, Psi_model, model_weights_0, model_BT,\n","                                terms, all_lam_x[kk], all_lam_y[kk], all_lam_y[kk], all_Sigma_yy[kk], Stress_predicted[kk][1], R2y_all[kk],'y',kk,'combine')\n","            if kk==4: #y plot: strip-y\n","                ax2 = fig3.add_subplot(spec3[1,kk-1])\n","                areas=plotMap(fig3, ax2, Psi_model, model_weights_0, model_BT,\n","                                terms, all_lam_x[kk], all_lam_y[kk], all_lam_y[kk], all_Sigma_yy[kk], Stress_predicted[kk][1], R2y_all[kk],'y',kk-1,'combine')\n","            if kk==0:\n","                fig3.legend(handles=areas,loc='outside lower center', ncol=12, frameon=False)\n","            fig3.tight_layout()\n","            plt.tight_layout()\n","        plt.subplots_adjust(bottom=0.2)\n","        plt.savefig(path2saveResults+'//Plot_PI-CANN_MAP_'+'all'+'.pdf')\n","        plt.close()\n","\n","    # Storing data\n","    Config = {modelFit_mode:modelFit_mode, \"R2_x1\":R2x_all[0], \"R2_x2\": R2x_all[1], \"R2_x3\": R2x_all[2], \"R2_x4\": R2x_all[3], \"R2_x5\": R2x_all[4],\n","            \"R2_y1\":R2y_all[0], \"R2_y2\": R2y_all[1], \"R2_y3\": R2y_all[2], \"R2_y4\": R2y_all[3], \"R2_y5\": R2y_all[4],\n","            \"weights\": weight_matrix.tolist()}\n","    json.dump(Config, open(path2saveResults+\"//Config_file.txt\",'w'))\n","\n","    weight_matrix_new1 = weight_matrix[:,0]*weight_matrix[:,1]\n","    weight_matrix_new2 = weight_matrix\n","    weight_matrix_new2[np.where(weight_matrix_new1 == 0)[0], :] = [0,0]\n","\n","    numcol = np.arange(23)+1\n","    func = ['I1','exp(I1)','I1^2','exp(I1^2)',\n","            'I2','exp(I2)','I2^2', 'exp(I2^2)']\n","    list_of_tuples = list(zip(numcol,func,weight_matrix_new2))\n","    df = pd.DataFrame(list_of_tuples , columns=['Count','Function', 'Weight'])\n","    df.to_csv(path2saveResults+\"//Config_file_new.txt\", sep='\\t', index=False)\n","\n","    R2_all[:,id1] = np.array(R2x_all + R2y_all)\n","\n","    if modelFit_mode=='all':\n","        R2x_p = statistics.mean(R2x_all)\n","        R2y_p = statistics.mean(R2y_all)\n","    else:\n","        R2x_p = R2x_all[id1-1]\n","        R2y_p = R2y_all[id1-1]\n","\n","    R2_pick[0,id1] = R2x_p\n","    R2_pick[1,id1] = R2y_p\n","\n","    print(40*'=')\n","    print(\"Rx: \", R2x_p, \"|  Ry:\", R2y_p)\n","    print(40*'=')\n","\n","    print(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qUO7Ry472dDb"},"outputs":[],"source":[" # Create diagrams\n","def save_diagram(fig, ax, lamx, lamy, xplot, yplot_1, yplot_2, model_BT, model_weights, Psi_model, terms, label):\n","    # Save_Diagrams takes in 12 parameters to save NON-LABELED graphs with plots of the experimental data & resulting model\n","\n","         # [\"off-x\",\"off-y\",\"equi-biax\",\"strip-x\",\"strip-y\"] -- the different modes\n","\n","\n","        ax.plot(xplot, yplot_2, color='black', lw=4, zorder=1); # plot the model\n","        ax.scatter(xplot, yplot_1, edgecolor='black', facecolor='white', linewidth=3,s = 800, alpha=0.9, zorder=200, clip_on = False) # plot the experimental data\n","\n","\n","       # Running the Color Map Function to plot the colors for each term used in the model\n","\n","        tick_label = [r'$I_1$',r'$\\exp(I_1)$',r'$I_1^2$',r'$\\exp(I_1^2)$', # tick_label is needed to run the color_map function\n","                  r'$I_2$',r'$\\exp(I_2)$',r'$I_2^2$',r'$\\exp(I_2^2)$']\n","        cmap = plt.cm.get_cmap('jet',8)\n","        cmaplist = [cmap(i) for i in range(cmap.N)]\n","        color_map(ax, lamx, lamy, xplot, model_BT, model_weights, Psi_model, cmaplist, terms, label,tick_label)\n","\n","\n","      # Extract max and min x/y-values for graph limits\n","        max_x = np.max(np.array(xplot))\n","        max_y = np.max(np.array(yplot_1))\n","        min_x = np.min(np.array(xplot))\n","        min_y = np.min(np.array(yplot_1))\n","\n","      # Graph limits and labels\n","        ax.set_xlim([min_x, max_x])\n","        ax.set_xticks([min_x, max_x])\n","        ax.set_xticklabels(['', ''])\n","\n","        ax.set_ylim([min_y, max_y])\n","        ax.set_yticks([min_y, max_y])\n","        ax.set_yticklabels(['', ''])\n","\n","      # Creates a new path called \"Diagrams\" to save all graphs\n","        newpath = path2saveResults + '/Diagrams/'\n","        if not os.path.exists(newpath):\n","           os.makedirs(newpath)\n","\n","      # Saves figure\n","        plt.savefig(newpath + title_name  + '.png', pad_inches = 2) # creates a padding white border so the dot plots dont get cut off\n","end\n","\n","# Each section creates a different figure. Manually select the lamx, lamy, xploy, yploy_1, yplot_2 within pre-existing variables. Calls save_diagram function to create untitled figures\n","\n","title_name =  'lx_off-x'   # \"lambda x, off-x diretion, \"\"\n","fig1, ax1 = plt.subplots(figsize=(12.5, 8.33))\n","lamx = all_lam_x[0]\n","lamy = all_lam_y[0]\n","xplot = all_lam_x[0]\n","yplot_1 = all_Sigma_xx[0]\n","yplot_2 = Stress_predicted[0][0]\n","save_diagram(fig1, ax1, lamx, lamy, xplot, yplot_1, yplot_2, model_BT, model_weights_0, Psi_model, terms, 'x')\n","\n","title_name =  'lx_off-y'   # \"lambda x  \" off-y diretion, \"\"\n","fig2, ax2 = plt.subplots(figsize=(12.5, 8.33))\n","lamx = all_lam_x[1]\n","lamy = all_lam_y[1]\n","xplot = all_lam_x[1]\n","yplot_1 = all_Sigma_xx[1]\n","yplot_2 = Stress_predicted[1][0]\n","save_diagram(fig2, ax2, lamx, lamy, xplot, yplot_1, yplot_2, model_BT, model_weights_0, Psi_model, terms, 'x')\n","\n","title_name =  'lx_equibiax'   # \" lambda x equi_biax diretion \"\"\n","fig3, ax3 = plt.subplots(figsize=(12.5, 8.33))\n","lamx = all_lam_x[2]\n","lamy = all_lam_y[2]\n","xplot = all_lam_x[2]\n","yplot_1 = all_Sigma_xx[2]\n","yplot_2 = Stress_predicted[2][0]\n","save_diagram(fig3, ax3, lamx, lamy, xplot, yplot_1, yplot_2, model_BT, model_weights_0, Psi_model, terms, 'x')\n","\n","title_name =  'lx_strip-xstrip-y'   #  lambd x, strip-xstripy diretion\"\"\n","fig4, ax4 = plt.subplots(figsize=(12.5, 8.33))\n","lamx = all_lam_x[3]\n","lamy = all_lam_y[3]\n","xplot = all_lam_x[3]\n","yplot_1 = all_Sigma_xx[3]\n","yplot_2 = Stress_predicted[3][0]\n","save_diagram(fig4, ax4, lamx, lamy, xplot, yplot_1, yplot_2, model_BT, model_weights_0, Psi_model, terms, 'x')\n","\n","title_name =  'ly_off-x'   # \"lambda y , off-x diretion,  \"\"\n","fig5, ax5 = plt.subplots(figsize=(12.5, 8.33))\n","lamx = all_lam_x[0]\n","lamy = all_lam_y[0]\n","xplot = all_lam_y[0]\n","yplot_1 = all_Sigma_yy[0]\n","yplot_2 = Stress_predicted[0][1]\n","save_diagram(fig5, ax5, lamx, lamy, xplot, yplot_1, yplot_2, model_BT, model_weights_0, Psi_model, terms, 'y')\n","\n","title_name =  'ly_off-y'   # \"lambda y, off-y diretion\"\"\n","fig6, ax6 = plt.subplots(figsize=(12.5, 8.33))\n","lamx = all_lam_x[1]\n","lamy = all_lam_y[1]\n","xplot = all_lam_y[1]\n","yplot_1 = all_Sigma_yy[1]\n","yplot_2 = Stress_predicted[1][1]\n","save_diagram(fig6, ax6, lamx, lamy, xplot, yplot_1, yplot_2, model_BT, model_weights_0, Psi_model, terms, 'y')\n","\n","title_name =  'ly_equibiax'   # \"lambda y, equi_biax diretion \"\"\n","fig7, ax7 = plt.subplots(figsize=(12.5, 8.33))\n","lamx = all_lam_x[2]\n","lamy = all_lam_y[2]\n","xplot = all_lam_y[2]\n","yplot_1 = all_Sigma_yy[2]\n","yplot_2 = Stress_predicted[2][1]\n","save_diagram(fig7, ax7, lamx, lamy, xplot, yplot_1, yplot_2, model_BT, model_weights_0, Psi_model, terms, 'y')\n","\n","title_name =  'ly_strip-xstrip-y'    # lambda y, strip-xstripy diretion \"\"\n","fig8, ax8 = plt.subplots(figsize=(12.5, 8.33))\n","lamx = all_lam_x[4]\n","lamy = all_lam_y[4]\n","xplot = all_lam_y[4]\n","yplot_1 = all_Sigma_yy[4]\n","yplot_2 = Stress_predicted[4][1]\n","save_diagram(fig8, ax8, lamx, lamy, xplot, yplot_1, yplot_2, model_BT, model_weights_0, Psi_model, terms, 'y')\n","\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"14THLZB4vFkUedfntZ9sOC5d9AQ1qXwv-","timestamp":1724348435953},{"file_id":"1Opn5GaqPtf5PT7SYumNOsXhMtgd_0WWz","timestamp":1724124825493}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}